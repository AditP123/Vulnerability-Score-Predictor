#!/usr/bin/env python
# coding: utf-8

# In[331]:


import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import pickle
from sklearn.preprocessing import MinMaxScaler


# In[332]:


### MCAS AADP


# In[333]:


DATASET_1_PATH = "Datasets"
filename = "MLInput_MCAS_AADP_cleaned.csv"
filepath = os.path.join(DATASET_1_PATH, filename)


# In[334]:


new_df = pd.read_csv("../Datasets/MLInput_MCAS_AADP_cleaned.csv", encoding = "cp1252")
features = ['UPN Count','IP Count', 'suspicious', 'deleted', 'failed']
scaler = StandardScaler()
new_df[[('normalized ' + feature) for feature in features ]] = scaler.fit_transform(new_df[features])
new_df.head()


# In[335]:


# Determine the optimal number of clusters using the elbow method
inertia = []
for n in range(1, 12):
    kmeans = KMeans(n_clusters=n, random_state=42)
    kmeans.fit(new_df[[('normalized ' + feature) for feature in features ]])
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.plot(range(1, 12), inertia)
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.show()


# In[336]:


optimal_clusters = 5
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
new_df['cluster'] = kmeans.fit_predict(new_df[[('normalized ' + feature) for feature in features ]])
new_df


# In[337]:


pca = PCA(n_components=2)  # Reduce to 2 dimensions for simplicity
principal_components = pca.fit_transform(new_df[[('normalized ' + feature) for feature in features]])

# Add the principal components to the DataFrame
new_df['PC1'] = principal_components[:, 0]
new_df['PC2'] = principal_components[:, 1]

pca_centroids = pca.transform(kmeans.cluster_centers_)

def euclidean_distance_pca(point, centroid):
    return np.linalg.norm(point - centroid)

new_df['vulnerability_score'] = new_df.apply(
    lambda row: euclidean_distance_pca(row[['PC1', 'PC2']], pca_centroids[int(row['cluster'])]), axis=1
)


# In[338]:


new_df


# In[339]:


new_df.to_csv('../Datasets/MLInput_MCAS_AADP_cleaned_KMeans.csv')


# In[340]:


with open('../Models/Unsupervised/KMEANS_MCAS_AADP.pkl','wb') as f:
    pickle.dump(kmeans,f) #Put the name of the variable of the model here


# In[341]:


### ATP TI


# In[342]:


DATASET_2_PATH = "Datasets"
filename = "MLInput_ATP_TI_cleaned.csv"
filepath = os.path.join(DATASET_2_PATH, filename)

df = pd.read_csv("../Datasets/MLInput_ATP_TI_cleaned.csv", encoding = "cp1252")
features = ['UPN Count','IP Count', 'Description New_Brand impersonation', 'Description New_Malicious URL reputation', 'Description New_Malware', 'Description New_Threats']
scaler = StandardScaler()
df[[('normalized ' + feature) for feature in features ]] = scaler.fit_transform(df[features])
df.head()


# In[343]:


# Determine the optimal number of clusters using the elbow method
inertia = []
for n in range(1, 20):
    kmeans = KMeans(n_clusters=n, random_state=42)
    kmeans.fit(df[[('normalized ' + feature) for feature in features ]])
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.plot(range(1, 20), inertia)
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.show()


# In[344]:


#6 or 10


# In[345]:


optimal_clusters = 10
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
df['cluster'] = kmeans.fit_predict(df[[('normalized ' + feature) for feature in features ]])
df


# In[346]:


# Get the cluster centroids
centroids = kmeans.cluster_centers_

# Calculate the distance of each point from its cluster centroid
df['vulnerability_score'] = df.apply(
    lambda row: euclidean_distance(row[[('normalized ' + feature) for feature in features ]], centroids[int(row['cluster'])]), axis=1
)


# In[347]:


pca = PCA(n_components=2)  # Reduce to 2 dimensions for simplicity
principal_components = pca.fit_transform(df[[('normalized ' + feature) for feature in features ]])

# Add the principal components to the DataFrame
df['PC1'] = principal_components[:, 0]
df['PC2'] = principal_components[:, 1]

pca_centroids = pca.transform(kmeans.cluster_centers_)

df['vulnerability_score'] = df.apply(
    lambda row: euclidean_distance_pca(row[['PC1', 'PC2']], pca_centroids[int(row['cluster'])]), axis=1
)

df.to_csv('../Datasets/MLInput_ATP_TI_cleaned_KMeans.csv')


# In[348]:


with open('../Models/Unsupervised/KMEANS_ATP_TI.pkl','wb') as f:
    pickle.dump(kmeans,f) #Put the name of the variable of the model here

