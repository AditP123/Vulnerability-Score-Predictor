#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, median_absolute_error
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


# In[2]:


# Define the MLP regressor model
class MLPRegressor(nn.Module):
    def __init__(self):
        super(MLPRegressor, self).__init__()
        self.hidden1 = nn.Linear(1, 64)  # input layer to first hidden layer
        self.hidden2 = nn.Linear(64, 32) # first hidden layer to second hidden layer
        self.output = nn.Linear(32, 1)   # second hidden layer to output layer

    def forward(self, x):
        x = torch.relu(self.hidden1(x))
        x = torch.relu(self.hidden2(x))
        x = self.output(x)
        return x


# In[3]:


df = pd.read_csv("/content/ATP_TI_MCAS_AADP.csv")
df = df.dropna()
df.info()


# In[4]:


X = df[['UPN Count']].values.astype(np.float32)
Y = df[['AvgProbability']].values.astype(np.float32)
scaler = StandardScaler()


# In[5]:


x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)


# In[6]:


# Convert to PyTorch tensors
X_train_tensor = torch.from_numpy(x_train)
y_train_tensor = torch.from_numpy(y_train)
X_test_tensor = torch.from_numpy(x_test)
y_test_tensor = torch.from_numpy(y_test)


# In[7]:


# Initialize the model, define the loss function and the optimizer
model = MLPRegressor()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 1000
for epoch in range(num_epochs):
    model.train()

    # Zero the gradient buffers
    optimizer.zero_grad()

    # Forward pass
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)

    # Backward pass and optimize
    loss.backward()
    optimizer.step()

    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Switch to evaluation mode
model.eval()


# In[8]:


# Make predictions on the test set
with torch.no_grad():
    predictions = model(X_test_tensor)
    test_loss = criterion(predictions, y_test_tensor)
    print(f'Test Loss: {test_loss.item():.4f}')

# Example prediction for a new input
new_input = np.array([[0.5]], dtype=np.float32)
new_input_tensor = torch.from_numpy(new_input)
with torch.no_grad():
    new_prediction = model(new_input_tensor)


# In[9]:


metrics_df = pd.DataFrame(columns=["Model", "MAE", "MSE", "R-squared", "RMSE", "Median AE"])
def metrics(df, model, y_test, predictions):
    metric_list = [model, mean_absolute_error(y_test, predictions), mean_squared_error(y_test, predictions), r2_score(y_test, predictions),  np.sqrt(mean_squared_error(y_test, predictions)), median_absolute_error(y_test, predictions) ]
    print(metric_list)
    df.loc[len(df)] = metric_list


# In[10]:


metrics(metrics_df, "MLP", y_test, predictions.numpy())


# In[11]:


pd.options.display.float_format = '{:.05f}'.format
metrics_df.head(15)


# In[12]:


get_ipython().run_line_magic('matplotlib', 'inline')
plt.xlabel('Threat Count')
plt.ylabel('AvgProbability Score')
plt.scatter(x_test, y_test, color='red', label="Actual")
plt.scatter(x_test, predictions.numpy(),  color='blue', label="Predicted")
plt.title("MLP Regressor")
plt.legend()


# In[13]:


model.state_dict()


# In[15]:


torch.save(model.state_dict(), '/content/model_weights.pth')


# In[ ]:


#Load Model

model = MLPRegressor() # we do not specify ``weights``, i.e. create untrained model
model.load_state_dict(torch.load('../../Models/Neural Network/model_weights.pth'))
model.eval()


# In[ ]:




