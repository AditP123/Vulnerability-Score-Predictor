{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor, ElasticNet, Lars, Lasso, OrthogonalMatchingPursuit, ARDRegression, MultiTaskElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Datasets/Supervised Learning Inputs/ATP_TI_MCAS_AADP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435 entries, 0 to 434\n",
      "Data columns (total 13 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Unnamed: 0_x                               435 non-null    float64\n",
      " 1   UPN                                        435 non-null    object \n",
      " 2   Brand impersonation                        435 non-null    float64\n",
      " 3   Malicious URL reputation                   435 non-null    float64\n",
      " 4   Malware                                    435 non-null    float64\n",
      " 5   Threats                                    435 non-null    float64\n",
      " 6   Unnamed: 0_y                               435 non-null    float64\n",
      " 7   Delete messages from Deleted Items folder  435 non-null    float64\n",
      " 8   Failed log on                              435 non-null    float64\n",
      " 9   Suspicious Email                           435 non-null    float64\n",
      " 10  Threat Count                               435 non-null    float64\n",
      " 11  AvgProbability                             435 non-null    float64\n",
      " 12  UPN Count                                  435 non-null    float64\n",
      "dtypes: float64(12), object(1)\n",
      "memory usage: 44.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:, 0:6] # not taking threat count\n",
    "X = df[['UPN Count']] #  taking upn and threat count\n",
    "Y = df[['AvgProbability']]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435 entries, 0 to 434\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   UPN Count  435 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 435 entries, 0 to 434\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   AvgProbability  435 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n",
    "Y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression() # Linear Regression Model\n",
    "ridge_regression = Ridge(alpha=0.5)\n",
    "polynomial_regression = LinearRegression()\n",
    "svr = svm.SVR(C=1.0, epsilon=0.2)\n",
    "decision_tree = DecisionTreeRegressor(max_depth=50)\n",
    "random_forest = RandomForestRegressor(n_estimators=10, max_features=2, max_leaf_nodes=20,random_state=42)\n",
    "sgd_regressor = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "elastic_net = ElasticNet(random_state=0)\n",
    "lars = Lars(n_nonzero_coefs=1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "omp_regression = OrthogonalMatchingPursuit()\n",
    "ard_regression = ARDRegression()\n",
    "# multitask_elastic_net = MultiTaskElasticNet(alpha=0.1)\n",
    "krr = krr = KernelRidge(alpha=1.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "metrics_df = pd.DataFrame(columns=[\"Model\", \"MAE\", \"MSE\", \"R-squared\", \"RMSE\", \"Median AE\"])\n",
    "# metrics_df.set_index('Model', inplace=True)\n",
    "# predictions_df[\"UPN\"] = x_test['UPN']\n",
    "predictions_df[\"Real Predictions\"] = y_test\n",
    "\n",
    "model_map = {\n",
    "    linear_regression: \"Linear Regression\",\n",
    "    ridge_regression: \"Ridge Regression\",\n",
    "    polynomial_regression: \"Polynomial Regression\",\n",
    "    svr: \"Support Vector Regressor\",\n",
    "    decision_tree: \"Decision Tree Regressor\",\n",
    "    random_forest: \"Random Forest Regressor\",\n",
    "    sgd_regressor: \"Stochastic Gradient Descent Regressor\",\n",
    "    elastic_net: \"Elastic Net Regressor\",\n",
    "    lars: \"Lars\",\n",
    "    lasso: \"Lasso\",\n",
    "    omp_regression: \"Orthogonal Matching Pursuit Regressor\",\n",
    "    ard_regression: \"Bayesian ARD Regression\",\n",
    "    # multitask_elastic_net: \"Multitask Elastic Net Regressor\",\n",
    "    krr: \"Kernel Ridge Regressor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(df, model, y_test, predictions):\n",
    "    metric_list = [model_map[model], mean_absolute_error(y_test, predictions), mean_squared_error(y_test, predictions), r2_score(y_test, predictions),  np.sqrt(mean_squared_error(y_test, predictions)), median_absolute_error(y_test, predictions) ]\n",
    "    print(metric_list)\n",
    "    df.loc[len(df)] = metric_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = x_test.iloc[:,6:]\n",
    "# # X_train = x_train.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [linear_regression, ridge_regression, polynomial_regression, svr, decision_tree, random_forest, sgd_regressor, lars, lasso, omp_regression, ard_regression,  krr] #multitask_elastic_net,\n",
    "\n",
    "\n",
    "\n",
    "def model_test_eval(model,x_train,x_test,y_train,y_test):\n",
    "    if model == polynomial_regression:\n",
    "        # model.fit(poly_features.fit_transform(x_train.iloc[:,2:]), y_train)\n",
    "        # predictions = model.predict(poly_features.fit_transform(x_test.iloc[:,2:]))\n",
    "        # model.fit(poly_features.fit_transform(x_train), y_train)\n",
    "        model.fit(poly_features.fit_transform(x_train), y_train)\n",
    "        predictions = model.predict(poly_features.fit_transform(x_test))\n",
    "        predictions_df[f\"{model_map[model]}  Predictions\"] = predictions\n",
    "        # metrics(metrics_df, model, y_test, predictions)\n",
    "        metrics(metrics_df, model, y_test, predictions)\n",
    "\n",
    "    elif model == linear_regression:\n",
    "        # model.fit(x_train.iloc[:,2:], y_train)\n",
    "        # predictions = model.predict(x_test.iloc[:,2:])\n",
    "        model.fit(x_train, y_train)\n",
    "        predictions = model.predict(x_test)\n",
    "        predictions_df[f\"{model_map[model]} Predictions\"] = predictions\n",
    "        metrics(metrics_df, model, y_test, predictions)\n",
    "\n",
    "    else:\n",
    "        # model.fit(scaler.fit_transform(x_train.iloc[:,2:]), y_train)\n",
    "        # predictions = model.predict(scaler.fit_transform(x_test.iloc[:,2:]))\n",
    "        # model.fit(scaler.fit_transform(x_train), y_train)\n",
    "        model.fit(scaler.fit_transform(x_train), y_train)\n",
    "        predictions = model.predict(scaler.fit_transform(x_test))\n",
    "        predictions_df[f\"{model_map[model]} Predictions\"] = predictions\n",
    "        # metrics(metrics_df, model, y_test, predictions)\n",
    "        metrics(metrics_df, model, y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Regression', 0.05108747323065059, 0.01303508077113039, 0.0010748652409432458, 0.11417127822324838, 0.03583849608608858]\n",
      "['Ridge Regression', 0.0508017277279017, 0.012989124381347592, 0.004596668723626185, 0.11396983978819832, 0.03602005343440762]\n",
      "['Polynomial Regression', 0.05105472709069916, 0.012986280214446977, 0.004814627465452026, 0.11395736138770052, 0.03686108846353331]\n",
      "['Support Vector Regressor', 0.14163888291502982, 0.026869031704194895, -1.0590705640584002, 0.16391775896526556, 0.1380524894101749]\n",
      "['Decision Tree Regressor', 0.05539024613271234, 0.013652665499700564, -0.04625287434456293, 0.11684462118429143, 0.037627272727273064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ragha\\AppData\\Local\\Temp\\ipykernel_29896\\3749777033.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(scaler.fit_transform(x_train), y_train)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29896\\84387410.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel_test_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29896\\3749777033.py\u001b[0m in \u001b[0;36mmodel_test_eval\u001b[1;34m(model, x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# predictions = model.predict(scaler.fit_transform(x_test.iloc[:,2:]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# model.fit(scaler.fit_transform(x_train), y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mpredictions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{model_map[model]} Predictions\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ragha\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_test_eval(model,x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Predictions</th>\n",
       "      <th>Linear Regression Predictions</th>\n",
       "      <th>Ridge Regression Predictions</th>\n",
       "      <th>Polynomial Regression  Predictions</th>\n",
       "      <th>Support Vector Regressor Predictions</th>\n",
       "      <th>Decision Tree Regressor Predictions</th>\n",
       "      <th>Random Forest Regressor Predictions</th>\n",
       "      <th>Stochastic Gradient Descent Regressor Predictions</th>\n",
       "      <th>Lars Predictions</th>\n",
       "      <th>Lasso Predictions</th>\n",
       "      <th>Orthogonal Matching Pursuit Regressor Predictions</th>\n",
       "      <th>Bayesian ARD Regression Predictions</th>\n",
       "      <th>Kernel Ridge Regressor Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.81600</td>\n",
       "      <td>0.78112</td>\n",
       "      <td>0.77888</td>\n",
       "      <td>0.77804</td>\n",
       "      <td>0.64715</td>\n",
       "      <td>0.76303</td>\n",
       "      <td>0.75478</td>\n",
       "      <td>0.77770</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.80140</td>\n",
       "      <td>0.78166</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78064</td>\n",
       "      <td>0.66605</td>\n",
       "      <td>0.79581</td>\n",
       "      <td>0.79573</td>\n",
       "      <td>0.78008</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.82300</td>\n",
       "      <td>0.78547</td>\n",
       "      <td>0.79948</td>\n",
       "      <td>0.79763</td>\n",
       "      <td>0.66801</td>\n",
       "      <td>0.85050</td>\n",
       "      <td>0.84505</td>\n",
       "      <td>0.79671</td>\n",
       "      <td>0.79950</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.79950</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.01684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.72240</td>\n",
       "      <td>0.78112</td>\n",
       "      <td>0.77888</td>\n",
       "      <td>0.77804</td>\n",
       "      <td>0.64715</td>\n",
       "      <td>0.76303</td>\n",
       "      <td>0.75478</td>\n",
       "      <td>0.77770</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.78150</td>\n",
       "      <td>0.78220</td>\n",
       "      <td>0.78403</td>\n",
       "      <td>0.78320</td>\n",
       "      <td>0.68693</td>\n",
       "      <td>0.80135</td>\n",
       "      <td>0.80080</td>\n",
       "      <td>0.78246</td>\n",
       "      <td>0.78403</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78403</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.00142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Real Predictions  Linear Regression Predictions  \\\n",
       "280           0.81600                        0.78112   \n",
       "78            0.80140                        0.78166   \n",
       "113           0.82300                        0.78547   \n",
       "253           0.72240                        0.78112   \n",
       "324           0.78150                        0.78220   \n",
       "\n",
       "     Ridge Regression Predictions  Polynomial Regression  Predictions  \\\n",
       "280                       0.77888                             0.77804   \n",
       "78                        0.78145                             0.78064   \n",
       "113                       0.79948                             0.79763   \n",
       "253                       0.77888                             0.77804   \n",
       "324                       0.78403                             0.78320   \n",
       "\n",
       "     Support Vector Regressor Predictions  \\\n",
       "280                               0.64715   \n",
       "78                                0.66605   \n",
       "113                               0.66801   \n",
       "253                               0.64715   \n",
       "324                               0.68693   \n",
       "\n",
       "     Decision Tree Regressor Predictions  Random Forest Regressor Predictions  \\\n",
       "280                              0.76303                              0.75478   \n",
       "78                               0.79581                              0.79573   \n",
       "113                              0.85050                              0.84505   \n",
       "253                              0.76303                              0.75478   \n",
       "324                              0.80135                              0.80080   \n",
       "\n",
       "     Stochastic Gradient Descent Regressor Predictions  Lars Predictions  \\\n",
       "280                                            0.77770           0.77887   \n",
       "78                                             0.78008           0.78145   \n",
       "113                                            0.79671           0.79950   \n",
       "253                                            0.77770           0.77887   \n",
       "324                                            0.78246           0.78403   \n",
       "\n",
       "     Lasso Predictions  Orthogonal Matching Pursuit Regressor Predictions  \\\n",
       "280            0.78261                                            0.77887   \n",
       "78             0.78261                                            0.78145   \n",
       "113            0.78261                                            0.79950   \n",
       "253            0.78261                                            0.77887   \n",
       "324            0.78261                                            0.78403   \n",
       "\n",
       "     Bayesian ARD Regression Predictions  Kernel Ridge Regressor Predictions  \n",
       "280                              0.78261                            -0.00373  \n",
       "78                               0.78261                            -0.00116  \n",
       "113                              0.78261                             0.01684  \n",
       "253                              0.78261                            -0.00373  \n",
       "324                              0.78261                             0.00142  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Predictions</th>\n",
       "      <th>Linear Regression Predictions</th>\n",
       "      <th>Ridge Regression Predictions</th>\n",
       "      <th>Polynomial Regression  Predictions</th>\n",
       "      <th>Support Vector Regressor Predictions</th>\n",
       "      <th>Decision Tree Regressor Predictions</th>\n",
       "      <th>Random Forest Regressor Predictions</th>\n",
       "      <th>Stochastic Gradient Descent Regressor Predictions</th>\n",
       "      <th>Lars Predictions</th>\n",
       "      <th>Lasso Predictions</th>\n",
       "      <th>Orthogonal Matching Pursuit Regressor Predictions</th>\n",
       "      <th>Bayesian ARD Regression Predictions</th>\n",
       "      <th>Kernel Ridge Regressor Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>109.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.77938</td>\n",
       "      <td>0.78190</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78169</td>\n",
       "      <td>0.66184</td>\n",
       "      <td>0.78289</td>\n",
       "      <td>0.77799</td>\n",
       "      <td>0.78115</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.11476</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.00577</td>\n",
       "      <td>0.00545</td>\n",
       "      <td>0.01397</td>\n",
       "      <td>0.02286</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.00578</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00578</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.78112</td>\n",
       "      <td>0.77888</td>\n",
       "      <td>0.77804</td>\n",
       "      <td>0.64715</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.73992</td>\n",
       "      <td>0.77770</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.75620</td>\n",
       "      <td>0.78112</td>\n",
       "      <td>0.77888</td>\n",
       "      <td>0.77804</td>\n",
       "      <td>0.64715</td>\n",
       "      <td>0.76303</td>\n",
       "      <td>0.75478</td>\n",
       "      <td>0.77770</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.77887</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.79890</td>\n",
       "      <td>0.78166</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78064</td>\n",
       "      <td>0.66605</td>\n",
       "      <td>0.79581</td>\n",
       "      <td>0.79205</td>\n",
       "      <td>0.78008</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.82700</td>\n",
       "      <td>0.78166</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78064</td>\n",
       "      <td>0.66605</td>\n",
       "      <td>0.79581</td>\n",
       "      <td>0.79573</td>\n",
       "      <td>0.78008</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.78145</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>-0.00116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.85930</td>\n",
       "      <td>0.78874</td>\n",
       "      <td>0.81493</td>\n",
       "      <td>0.81047</td>\n",
       "      <td>0.69042</td>\n",
       "      <td>0.85050</td>\n",
       "      <td>0.84945</td>\n",
       "      <td>0.81097</td>\n",
       "      <td>0.81498</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.81498</td>\n",
       "      <td>0.78261</td>\n",
       "      <td>0.03227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Real Predictions  Linear Regression Predictions  \\\n",
       "count         109.00000                      109.00000   \n",
       "mean            0.77938                        0.78190   \n",
       "std             0.11476                        0.00122   \n",
       "min             0.00000                        0.78112   \n",
       "25%             0.75620                        0.78112   \n",
       "50%             0.79890                        0.78166   \n",
       "75%             0.82700                        0.78166   \n",
       "max             0.85930                        0.78874   \n",
       "\n",
       "       Ridge Regression Predictions  Polynomial Regression  Predictions  \\\n",
       "count                     109.00000                           109.00000   \n",
       "mean                        0.78261                             0.78169   \n",
       "std                         0.00577                             0.00545   \n",
       "min                         0.77888                             0.77804   \n",
       "25%                         0.77888                             0.77804   \n",
       "50%                         0.78145                             0.78064   \n",
       "75%                         0.78145                             0.78064   \n",
       "max                         0.81493                             0.81047   \n",
       "\n",
       "       Support Vector Regressor Predictions  \\\n",
       "count                             109.00000   \n",
       "mean                                0.66184   \n",
       "std                                 0.01397   \n",
       "min                                 0.64715   \n",
       "25%                                 0.64715   \n",
       "50%                                 0.66605   \n",
       "75%                                 0.66605   \n",
       "max                                 0.69042   \n",
       "\n",
       "       Decision Tree Regressor Predictions  \\\n",
       "count                            109.00000   \n",
       "mean                               0.78289   \n",
       "std                                0.02286   \n",
       "min                                0.73750   \n",
       "25%                                0.76303   \n",
       "50%                                0.79581   \n",
       "75%                                0.79581   \n",
       "max                                0.85050   \n",
       "\n",
       "       Random Forest Regressor Predictions  \\\n",
       "count                            109.00000   \n",
       "mean                               0.77799   \n",
       "std                                0.02423   \n",
       "min                                0.73992   \n",
       "25%                                0.75478   \n",
       "50%                                0.79205   \n",
       "75%                                0.79573   \n",
       "max                                0.84945   \n",
       "\n",
       "       Stochastic Gradient Descent Regressor Predictions  Lars Predictions  \\\n",
       "count                                          109.00000         109.00000   \n",
       "mean                                             0.78115           0.78261   \n",
       "std                                              0.00533           0.00578   \n",
       "min                                              0.77770           0.77887   \n",
       "25%                                              0.77770           0.77887   \n",
       "50%                                              0.78008           0.78145   \n",
       "75%                                              0.78008           0.78145   \n",
       "max                                              0.81097           0.81498   \n",
       "\n",
       "       Lasso Predictions  Orthogonal Matching Pursuit Regressor Predictions  \\\n",
       "count          109.00000                                          109.00000   \n",
       "mean             0.78261                                            0.78261   \n",
       "std              0.00000                                            0.00578   \n",
       "min              0.78261                                            0.77887   \n",
       "25%              0.78261                                            0.77887   \n",
       "50%              0.78261                                            0.78145   \n",
       "75%              0.78261                                            0.78145   \n",
       "max              0.78261                                            0.81498   \n",
       "\n",
       "       Bayesian ARD Regression Predictions  Kernel Ridge Regressor Predictions  \n",
       "count                            109.00000                           109.00000  \n",
       "mean                               0.78261                            -0.00000  \n",
       "std                                0.00000                             0.00576  \n",
       "min                                0.78261                            -0.00373  \n",
       "25%                                0.78261                            -0.00373  \n",
       "50%                                0.78261                            -0.00116  \n",
       "75%                                0.78261                            -0.00116  \n",
       "max                                0.78261                             0.03227  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Median AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.05109</td>\n",
       "      <td>0.01304</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.11417</td>\n",
       "      <td>0.03584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.11397</td>\n",
       "      <td>0.03602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>0.05105</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.11396</td>\n",
       "      <td>0.03686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Regressor</td>\n",
       "      <td>0.14164</td>\n",
       "      <td>0.02687</td>\n",
       "      <td>-1.05907</td>\n",
       "      <td>0.16392</td>\n",
       "      <td>0.13805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.05539</td>\n",
       "      <td>0.01365</td>\n",
       "      <td>-0.04625</td>\n",
       "      <td>0.11684</td>\n",
       "      <td>0.03763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.05633</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.11717</td>\n",
       "      <td>0.03407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Descent Regressor</td>\n",
       "      <td>0.05120</td>\n",
       "      <td>0.01298</td>\n",
       "      <td>0.00492</td>\n",
       "      <td>0.11395</td>\n",
       "      <td>0.03722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lars</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.11397</td>\n",
       "      <td>0.03603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.05097</td>\n",
       "      <td>0.01306</td>\n",
       "      <td>-0.00080</td>\n",
       "      <td>0.11428</td>\n",
       "      <td>0.03469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Orthogonal Matching Pursuit Regressor</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.11397</td>\n",
       "      <td>0.03603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bayesian ARD Regression</td>\n",
       "      <td>0.05097</td>\n",
       "      <td>0.01306</td>\n",
       "      <td>-0.00080</td>\n",
       "      <td>0.11428</td>\n",
       "      <td>0.03469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kernel Ridge Regressor</td>\n",
       "      <td>0.77938</td>\n",
       "      <td>0.62041</td>\n",
       "      <td>-46.54427</td>\n",
       "      <td>0.78766</td>\n",
       "      <td>0.79743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model     MAE     MSE  R-squared    RMSE  \\\n",
       "0                       Linear Regression 0.05109 0.01304    0.00107 0.11417   \n",
       "1                        Ridge Regression 0.05080 0.01299    0.00460 0.11397   \n",
       "2                   Polynomial Regression 0.05105 0.01299    0.00481 0.11396   \n",
       "3                Support Vector Regressor 0.14164 0.02687   -1.05907 0.16392   \n",
       "4                 Decision Tree Regressor 0.05539 0.01365   -0.04625 0.11684   \n",
       "5                 Random Forest Regressor 0.05633 0.01373   -0.05215 0.11717   \n",
       "6   Stochastic Gradient Descent Regressor 0.05120 0.01298    0.00492 0.11395   \n",
       "7                                    Lars 0.05080 0.01299    0.00460 0.11397   \n",
       "8                                   Lasso 0.05097 0.01306   -0.00080 0.11428   \n",
       "9   Orthogonal Matching Pursuit Regressor 0.05080 0.01299    0.00460 0.11397   \n",
       "10                Bayesian ARD Regression 0.05097 0.01306   -0.00080 0.11428   \n",
       "11                 Kernel Ridge Regressor 0.77938 0.62041  -46.54427 0.78766   \n",
       "\n",
       "    Median AE  \n",
       "0     0.03584  \n",
       "1     0.03602  \n",
       "2     0.03686  \n",
       "3     0.13805  \n",
       "4     0.03763  \n",
       "5     0.03407  \n",
       "6     0.03722  \n",
       "7     0.03603  \n",
       "8     0.03469  \n",
       "9     0.03603  \n",
       "10    0.03469  \n",
       "11    0.79743  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.05f}'.format\n",
    "metrics_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD Regressors seems to be the most suitable fit to the given dataset with low MAE, MSE, RMSE values and with a positive R-squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save\n",
    "# for model in models:\n",
    "#     with open(f'../../Models/Supervised/{model_map[model]}.pkl','wb') as f:\n",
    "#         pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291541c09d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.xlabel('Threat Count')\n",
    "plt.ylabel('AvgProbability Score')\n",
    "plt.scatter(x_test.iloc[:,-1:], y_test, color='red', label=\"Actual\")\n",
    "plt.scatter(x_test.iloc[:,-1:], predictions_df['Stochastic Gradient Descent Regressor Predictions'],  color='blue', label=\"Predicted\")\n",
    "plt.title(\"SGD Regressor Plot\")\n",
    "# plt.plot(predictions_df['Stochastic Gradient Descent Regressor Predictions'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 173 entries, 0 to 176\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   Unnamed: 0                                 173 non-null    int64  \n",
      " 1   UPN                                        173 non-null    object \n",
      " 2   Delete messages from Deleted Items folder  173 non-null    int64  \n",
      " 3   Failed log on                              173 non-null    int64  \n",
      " 4   Suspicious Email                           173 non-null    int64  \n",
      " 5   UPN Count                                  173 non-null    int64  \n",
      " 6   Threat Count                               173 non-null    int64  \n",
      " 7   AvgProbability                             173 non-null    float64\n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(scaler.fit_transform(df.iloc[:,2:])).corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.07323</td>\n",
       "      <td>-0.04159</td>\n",
       "      <td>0.98040</td>\n",
       "      <td>0.98040</td>\n",
       "      <td>0.14035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07323</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04849</td>\n",
       "      <td>0.26746</td>\n",
       "      <td>0.26746</td>\n",
       "      <td>-0.01945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.04159</td>\n",
       "      <td>0.04849</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.01237</td>\n",
       "      <td>-0.01237</td>\n",
       "      <td>0.02986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98040</td>\n",
       "      <td>0.26746</td>\n",
       "      <td>-0.01237</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.13244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98040</td>\n",
       "      <td>0.26746</td>\n",
       "      <td>-0.01237</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.13244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.14035</td>\n",
       "      <td>-0.01945</td>\n",
       "      <td>0.02986</td>\n",
       "      <td>0.13244</td>\n",
       "      <td>0.13244</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5\n",
       "0  1.00000  0.07323 -0.04159  0.98040  0.98040  0.14035\n",
       "1  0.07323  1.00000  0.04849  0.26746  0.26746 -0.01945\n",
       "2 -0.04159  0.04849  1.00000 -0.01237 -0.01237  0.02986\n",
       "3  0.98040  0.26746 -0.01237  1.00000  1.00000  0.13244\n",
       "4  0.98040  0.26746 -0.01237  1.00000  1.00000  0.13244\n",
       "5  0.14035 -0.01945  0.02986  0.13244  0.13244  1.00000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
