
import pandas as pd
import numpy as np


df = pd.read_csv("../Datasets/Input/Text_Classification_Input.csv")


df['Description New'].value_counts()


def map_to_main_topics(df):
    # Define the mapping of subtopics to main topics
    topic_mapping = {
        'Unfamiliar sign-in properties': 'Authentication and Access Anomalies',
        'Anonymous IP address': 'Authentication and Access Anomalies',
        'Access from Malware linked IP address': 'Authentication and Access Anomalies',
        'Impossible Travel Activity': 'Authentication and Access Anomalies',
        'Access from infrequent location': 'Authentication and Access Anomalies',
        'Access from anonymous IP address': 'Authentication and Access Anomalies',
        'Failed Logon Activity': 'Authentication and Access Anomalies',
        'Failed log on': 'Authentication and Access Anomalies',
        
        'User impersonation': 'Impersonation and Phishing',
        'Brand impersonation': 'Impersonation and Phishing',
        'Domain impersonation': 'Impersonation and Phishing',
        'Suspicious email': 'Impersonation and Phishing',
        'Suspicious Email': 'Impersonation and Phishing',
        
        'Threats': 'Threats and Malicious Activity',
        'Malicious URL reputation': 'Threats and Malicious Activity',
        'Mass download by a single user': 'Threats and Malicious Activity',
        'Malware': 'Threats and Malicious Activity',
        
        'FileModifiedExtended': 'File and Search Activity',
        'FileAccessedExtended': 'File and Search Activity',
        'SearchQueryPerformed': 'File and Search Activity',
        'Delete messages from Deleted Items folder': 'File and Search Activity'
    }
    
    # Map subtopics to main topics
    df['Description Consolidated'] = df['Description New'].map(topic_mapping)
    
    return df


# Map subtopics to main topics
df = map_to_main_topics(df)



df.head()


df['Description Consolidated'].value_counts()


def select_random_samples(df, n):
    # Ensure there are enough samples for each group
    df_grouped = df.groupby('Description Consolidated', group_keys=False).apply(lambda x: x.sample(min(len(x), n)))
    return df_grouped


sampled_df = select_random_samples(df, 350)


sampled_df['Description Consolidated'].value_counts()


sampled_df.to_csv('../Datasets/Input/Text_Classification_Input_Cleaned.csv')

# [markdown]
# ### Testing Scoring Formula on Sample Final Input File - by Adit


test_df = pd.read_csv("C:/Users/Adit Prasad/Downloads/Sample Final_Input.csv", encoding = "cp1252")
test_df


test_df = map_to_main_topics(test_df)
test_df


grouped_data = test_df.groupby('UPN').agg(
    UPN_Count=('UPN', 'size'),
    Authentication_and_Access_Anomalies=('Description Consolidated', lambda x: (x == 'Authentication and Access Anomalies').sum()),
    Impersonation_and_Phishing=('Description Consolidated', lambda x: (x == 'Impersonation and Phishing').sum()),
    Threats_and_Malicious_Activity=('Description Consolidated', lambda x: (x == 'Threats and Malicious Activity').sum()),
    File_and_Search_Activity=('Description Consolidated', lambda x: (x == 'File and Search Activity').sum())
).reset_index()

grouped_data.rename(columns={'Authentication_and_Access_Anomalies': 'Authentication and Access Anomalies', 
                             'Impersonation_and_Phishing': 'Impersonation and Phishing',
                             'Threats_and_Malicious_Activity': 'Threats and Malicious Activity',
                             'File_and_Search_Activity': 'File and Search Activity'}, inplace=True)


grouped_data.to_csv("C:/Users/Adit Prasad/Downloads/Sample_Final_Input_Cleaned_Text_Classification.csv")


