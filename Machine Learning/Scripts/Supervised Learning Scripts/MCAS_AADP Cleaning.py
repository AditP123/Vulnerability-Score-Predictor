#!/usr/bin/env python
# coding: utf-8

# In[6]:


import os 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer


# In[7]:


df = pd.read_csv("../../../Machine Learning/Datasets/Input/MLInput_MCAS_AADP.csv", encoding = "cp1252")
#"../../../../Machine Learning/Datasets/Input/MLInput_MCAS_AADP.csv"


# In[8]:


df.info()


# In[9]:


df.drop(["Description", "Location",'Severity '], axis=1)


# In[10]:


def count_labels_by_upn(df, feature_column, upn_column):
    # Ensure the columns exist in the DataFrame
    if feature_column not in df.columns:
        raise ValueError(f"Column '{feature_column}' not found in DataFrame")
    if upn_column not in df.columns:
        raise ValueError(f"Column '{upn_column}' not found in DataFrame")
    
    # Create a new DataFrame to hold the counts
    counts_df = df.groupby(upn_column)[feature_column].value_counts().unstack(fill_value=0)
    
    # Add a column for the total count of occurrences for each UPN
    counts_df['UPN Count'] = counts_df.sum(axis=1)
    
    return counts_df

def sum_columns(df, columns_to_sum, new_column_name):

    # Check if columns_to_sum exist in the DataFrame
    for col in columns_to_sum:
        if col not in df.columns:
            raise ValueError(f"Column '{col}' does not exist in the DataFrame")
    
    # Sum the specified columns
    df[new_column_name] = df[columns_to_sum].sum(axis=1)


# In[11]:


count_df = count_labels_by_upn(df, 'Description New', 'UPN')


# In[12]:


count_df.info()


# In[13]:


sum_columns(count_df, ["Delete messages from Deleted Items folder", "Failed log on", "Suspicious Email"], "Threat Count")


# In[14]:


count_df.reset_index(inplace=True)


# In[15]:


count_df.info()


# In[16]:


df.nunique()


# In[17]:


def normalize_user_id(user_id):
    return user_id.split('@')[0]

def map_column_values(original_df, new_df, column_to_map, new_column_name):

    # Normalize User ID in both DataFrames
    original_df['UPN'] = original_df['UPN'].apply(normalize_user_id)
    new_df['UPN'] = new_df['UPN'].apply(normalize_user_id)
    
    # Merge the DataFrames on the normalized User ID
    merged_df = original_df.merge(new_df[['UPN', column_to_map]], 
                                  on='UPN', 
                                  how='left')
    
    # Rename the mapped column
    merged_df.rename(columns={column_to_map: new_column_name}, inplace=True)

    return merged_df



# In[18]:


op_df = pd.read_csv("../../Datasets/Output/MCAS_AADP_output.csv", encoding = "cp1252")


# In[22]:


final_df = map_column_values(count_df, op_df, 'AvgProbability', 'AvgProbability')


# In[23]:


final_df.head()


# In[25]:


#final_df.to_csv("../../Datasets/Supervised Learning Inputs/MCAS_AADP.csv")

