
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, median_absolute_error
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


class MLPRegressor(nn.Module):
    def __init__(self):
        super(MLPRegressor, self).__init__()
        self.hidden1 = nn.Linear(4, 64)  # input layer to first hidden layer
        self.hidden2 = nn.Linear(64, 32) # first hidden layer to second hidden layer
        self.output = nn.Linear(32, 1)   # second hidden layer to output layer

    def forward(self, x):
        x = torch.relu(self.hidden1(x))
        x = torch.relu(self.hidden2(x))
        x = self.output(x)
        return x


df = pd.read_csv("C:/Users/Adit Prasad/Downloads/Sample_Final_Input_Cleaned_Text_Classification_Output.csv")
df = df.dropna()
df.info()


X = df[['Authentication and Access Anomalies','Impersonation and Phishing','Threats and Malicious Activity','File and Search Activity']].values.astype(np.float32)
Y = df[['New Score']].values.astype(np.float32)
scaler = StandardScaler()


x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)


X_train_tensor = torch.from_numpy(x_train)
y_train_tensor = torch.from_numpy(y_train)
X_test_tensor = torch.from_numpy(x_test)
y_test_tensor = torch.from_numpy(y_test)


# Initialize the model, define the loss function and the optimizer
model = MLPRegressor()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 1000
for epoch in range(num_epochs):
    model.train()

    # Zero the gradient buffers
    optimizer.zero_grad()

    # Forward pass
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)

    # Backward pass and optimize
    loss.backward()
    optimizer.step()

    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Switch to evaluation mode
model.eval()


# Make predictions on the test set
with torch.no_grad():
    predictions = model(X_test_tensor)
    test_loss = criterion(predictions, y_test_tensor)
    print(f'Test Loss: {test_loss.item():.4f}')

# Example prediction for a new input
new_input = np.array([[0.5, 0.5, 0.5, 0.5]], dtype=np.float32)
new_input_tensor = torch.from_numpy(new_input)
with torch.no_grad():
    new_prediction = model(new_input_tensor)


metrics_df = pd.DataFrame(columns=["Model", "MAE", "MSE", "R-squared", "RMSE", "Median AE"])
def metrics(df, model, y_test, predictions):
    metric_list = [model, mean_absolute_error(y_test, predictions), mean_squared_error(y_test, predictions), r2_score(y_test, predictions),  np.sqrt(mean_squared_error(y_test, predictions)), median_absolute_error(y_test, predictions) ]
    print(metric_list)
    df.loc[len(df)] = metric_list


metrics(metrics_df, "MLP", y_test, predictions.numpy())


pd.options.display.float_format = '{:.05f}'.format
metrics_df.head(15)


model.state_dict()


torch.save(model.state_dict(), 'model_weights.pth')


#load model
model = MLPRegressor() # we do not specify ``weights``, i.e. create untrained model
model.load_state_dict(torch.load('../../../Backend/model_api/models/Neural Network/model_weights.pth'))
model.eval()





